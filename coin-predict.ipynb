{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done CG- ba1\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests_cache\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer,mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "import cryptocompare\n",
    "\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import ta\n",
    "\n",
    "# Define the parameter grid\n",
    "PARAM_GRID = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [6, 12, 24],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "RANDOM_PARAM_GRID = {\n",
    "    'n_estimators': [int(x) for x in range(50, 1000, 50)],\n",
    "    'max_depth': [None] + [int(x) for x in range(10, 110, 10)],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "XGB_PARAM_GRID= {\n",
    "    'n_estimators': [100, 500],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "BEST_PARAMS = {'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
    "\n",
    "voting_regressor = VotingRegressor([\n",
    "    ('lgr', LinearRegression()),\n",
    "    ('hist', HistGradientBoostingRegressor()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('gbm', GradientBoostingRegressor()),\n",
    "    # ('xgb', XGBRegressor())\n",
    "])\n",
    "\n",
    "ACTIVE_MODEL = Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    # ('FeatureSelection', SelectKBest(score_func=f_regression, k=10)),\n",
    "    ('Regressor', voting_regressor)\n",
    "    ]\n",
    ")\n",
    "# ACTIVE_MODEL = RandomForestRegressor(**BEST_PARAMS)\n",
    "# ACTIVE_MODEL=XGBRegressor(**{'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8})\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "PERIOD = 365\n",
    "DAYS_TO_BACKTEST = 4\n",
    "COINGECKO_KEY = os.getenv('COINGECKO_KEY')\n",
    "CC_KEY = os.getenv('CC_KEY')\n",
    "# format to 2 decimal in print\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print('done', COINGECKO_KEY[:3], CC_KEY[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CoinPredict:\n",
    "  COLS_TO_DROP = [\n",
    "    'Conversiontype', 'Conversionsymbol', 'Volumefrom', 'Volumeto',\n",
    "    'Range', 'Volume', 'High', 'Low', 'day of week', 'month', 'Dividends', 'Coin Splits', 'Capital Gains',]\n",
    "  TARGET_COL = 'target'\n",
    "  BASE_DIR = 'data'\n",
    "\n",
    "  def __init__(self, symbol='ETH', period=PERIOD, days_to_backtest=DAYS_TO_BACKTEST, use_additional_close_days=1, future_close_day_to_predict=1, max_features=14):\n",
    "    self.symbol = symbol\n",
    "    self.folder =  f\"{CoinPredict.BASE_DIR}/{self.symbol.lower()}\"\n",
    "    self.period = period\n",
    "    self.use_additional_close_days = use_additional_close_days\n",
    "    self.future_close_day_to_predict = future_close_day_to_predict\n",
    "    self.days_to_backtest = days_to_backtest\n",
    "    # https://github.com/man-c/pycoingecko\n",
    "    self.cg = CoinGeckoAPI(demo_api_key=COINGECKO_KEY)\n",
    "    cryptocompare.cryptocompare._set_api_key_parameter(CC_KEY)\n",
    "\n",
    "    self.selector_model = None\n",
    "    self.max_features = max_features\n",
    "\n",
    "  def get_coins_list(self):\n",
    "    coins = cryptocompare.get_coin_list(format=False)\n",
    "\n",
    "    # if file exists return\n",
    "    if os.path.exists(\"coins.json\"):\n",
    "      print(\"coins.json already exists\")\n",
    "    else:\n",
    "      with open(\"coins.json\", \"w\") as f:\n",
    "        f.write(json.dumps(coins))\n",
    "\n",
    "    symbol_file = \"coins_short.json\"\n",
    "    symbols = []\n",
    "    for k, v in coins.items():\n",
    "      symbols.append({\n",
    "        'id': v['Id'],\n",
    "        'symbol': v['Symbol'],\n",
    "        'name': v['Name']\n",
    "      })\n",
    "    with open(symbol_file, \"w\") as f:\n",
    "      f.write(json.dumps(symbols))\n",
    "\n",
    "\n",
    "  def load_data(self):\n",
    "    now = pd.Timestamp.now()\n",
    "    current_date_string = now.strftime('%Y-%m-%d')\n",
    "    data_file = f\"{self.folder}/{self.period}_{current_date_string}.csv\"\n",
    "    if not os.path.exists(self.folder):\n",
    "      # create folder if needed\n",
    "      os.makedirs(self.folder)\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "      print(\"loading data from file: \" + data_file)\n",
    "      # read 'Date' as index\n",
    "      df = pd.read_csv(data_file, header=0, index_col=0)\n",
    "    else:\n",
    "      from_timestamp = int((now - pd.Timedelta(days=int(self.period))).timestamp())\n",
    "      to_timestamp = int(now.timestamp())\n",
    "      print(\"loading data from coingecko\", from_timestamp, to_timestamp)\n",
    "      data = cryptocompare.get_historical_price_day(self.symbol, currency='USD',\n",
    "                                                    limit=365, toTs=to_timestamp)\n",
    "\n",
    "      # print('history metadata', self.ticker.history_metadata)\n",
    "      df = pd.DataFrame(data)\n",
    "      df.index = df['time'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "      # capitalize columns\n",
    "      df['volume'] = df['volumeto'] - df['volumefrom']\n",
    "      df.columns = [x.capitalize() for x in df.columns]\n",
    "\n",
    "    return self.process_data(df)\n",
    "\n",
    "  def get_last_quote(self):\n",
    "    if not COINGECKO_KEY:\n",
    "      return None\n",
    "\n",
    "    quote = cryptocompare.get_price(self.symbol, currency='USD', full=False)\n",
    "    quote['c'] = quote[self.symbol.upper()]['USD']\n",
    "    # now\n",
    "    quote['t'] = datetime.now().timestamp()\n",
    "\n",
    "    return quote\n",
    "\n",
    "\n",
    "  def process_data(self, df):\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "    # df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df['Range'] = df['High'] - df['Low']\n",
    "    for i in range(1, self.days_to_backtest):\n",
    "      df[f'close diff {i} days ago'] = df['Close'].shift(i-1) - df['Close'].shift(i)\n",
    "      df[f'volume {i} days ago'] = df['Volume'].shift(i)\n",
    "      df[f'range {i} days ago'] = df['Range'].shift(i)\n",
    "\n",
    "    # for i in range(1, self.use_additional_close_days):\n",
    "    #   df['Close +'+str(i)] = df['Close'].shift(-i)\n",
    "\n",
    "    df['high yesterday'] = df['High'].shift(1)\n",
    "    df['low yesterday'] = df['Low'].shift(1)\n",
    "\n",
    "    # df[CoinPredict.TARGET_COL] =  df['Close'].shift(-1) - df['Close'] # change in close\n",
    "    df[CoinPredict.TARGET_COL] = df['Close'].shift(-self.future_close_day_to_predict) # next close\n",
    "    # df[CoinPredict.TARGET_COL] = (df['Close'].shift(-1) - df['Open']).apply(lambda x: 'up' if x > 0 else 'down') # next close direction (up or down)\n",
    "\n",
    "    # set day of week\n",
    "    # as datetime\n",
    "    df['day of week'] = df.index.day_of_week\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    from ta import add_all_ta_features\n",
    "\n",
    "    df['EMA_5'] = ta.trend.ema_indicator(df['Close'], window=5)\n",
    "    df['EMA_20'] = ta.trend.ema_indicator(df['Close'], window=20)\n",
    "    # https://github.com/bukosabino/ta\n",
    "    df = add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
    "\n",
    "    # one hot encode month and day of week\n",
    "    # df = pd.get_dummies(df, columns=['day of week', 'month'])\n",
    "\n",
    "    # drop columns (final step)\n",
    "    cols_to_drop = CoinPredict.COLS_TO_DROP\n",
    "    # if last row is missing close, drop it\n",
    "    if pd.isna(df.iloc[-1]['Close']):\n",
    "      cols_to_drop.append('Close')\n",
    "\n",
    "    df = df.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "#     print('df columns', df.columns)\n",
    "    # fill nan with mean\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "    after_close = not pd.isna(df.iloc[-1]['Close'])\n",
    "\n",
    "    if not self.selector_model:\n",
    "      self.selector_model = RandomForestRegressor()\n",
    "      self.selector = SelectFromModel(self.selector_model, max_features=self.max_features, threshold=-np.inf) # take top max_features\n",
    "      # define X and y\n",
    "      X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "      y_train = df[CoinPredict.TARGET_COL]\n",
    "      self.selector_model.fit(X_train, y_train)\n",
    "      self.selector.fit(X_train, y_train)\n",
    "      # get selected columns\n",
    "\n",
    "    if hasattr(self.selector, 'get_support'):\n",
    "      selected_columns = X_train.columns[self.selector.get_support()]\n",
    "      # keep target\n",
    "      for col in [CoinPredict.TARGET_COL, 'Open', 'Close']:\n",
    "        if col not in selected_columns:\n",
    "          selected_columns = np.append(selected_columns, col)\n",
    "      print('selected columns', selected_columns)\n",
    "      df = df[selected_columns]\n",
    "\n",
    "    last_row = df.tail(1)\n",
    "\n",
    "    shift_days = self.future_close_day_to_predict - int(after_close)\n",
    "    df = df[self.days_to_backtest:]\n",
    "\n",
    "    print('shift', shift_days, after_close)\n",
    "    if shift_days > 0:\n",
    "      df = df[:-shift_days]\n",
    "\n",
    "    return df[:-1], last_row\n",
    "\n",
    "\n",
    "  def plot_data(self, df):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('Close Price History')\n",
    "    # plot with date\n",
    "    X = df.index\n",
    "    y = df['Close']\n",
    "    plt.plot(X,y)\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "  def train_model(self, df, debug=False):\n",
    "    # define X and y\n",
    "    X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    self.trained_columns = X_train.columns.values\n",
    "    if debug:\n",
    "      print('training shape', X_train.shape)\n",
    "      print('training columns', X_train.columns.values)\n",
    "    y_train = df[CoinPredict.TARGET_COL]\n",
    "    # split data\n",
    "\n",
    "    # create regressor\n",
    "    self.model = ACTIVE_MODEL#(**PARAMS)\n",
    "\n",
    "    # fit model\n",
    "    self.model.fit(X_train, y_train)\n",
    "    print('example train rows', y_train[-3:])\n",
    "\n",
    "  def param_search(self, df, random_search=True):\n",
    "    if not self.model:\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    # define X and y\n",
    "    X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    y_train = df[CoinPredict.TARGET_COL]\n",
    "    if random_search:\n",
    "      grid_search = RandomizedSearchCV(estimator=self.model,\n",
    "                                   param_distributions=XGB_PARAM_GRID,\n",
    "                                   n_iter=100,\n",
    "                                   cv=5,\n",
    "                                   verbose=2,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "    else:\n",
    "      grid_search = GridSearchCV(estimator=self.model, param_grid=PARAM_GRID,\n",
    "                            scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n",
    "    # Perform the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    return best_params, best_score\n",
    "\n",
    "  def cross_val_score(self, df, debug=False, cv=4):\n",
    "    if not hasattr(self, 'model'):\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    X = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    y = df[CoinPredict.TARGET_COL]\n",
    "    scores = cross_val_score(self.model, X, y, cv=cv)\n",
    "    print(f\"Symbol: {self.symbol} - Days to compare: {self.days_to_backtest}\\ncross val scores\\n---\\n{scores}\")\n",
    "\n",
    "    # print other stats\n",
    "    print(\"Average CV: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    model = ACTIVE_MODEL\n",
    "\n",
    "    # test train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mean_abs_error = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    if debug:\n",
    "      print('Mean Absolute Error:', mean_abs_error)\n",
    "      print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "      print('Root Mean Squared Error:', rmse)\n",
    "      print('R2 Score:', metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "    direction = y_pred - X_test['Open']\n",
    "    direction = direction.apply(lambda x: 'up' if x > 0 else 'down')\n",
    "    actual_direction = y_test - X_test['Open']\n",
    "    actual_direction = actual_direction.apply(lambda x: 'up' if x > 0 else 'down')\n",
    "\n",
    "    # print a few comparisons\n",
    "    print('Comparing a few predictions side by side...')\n",
    "    # percentage of predictions that are higher\n",
    "    print('Percentage of predictions that are up:', (direction == 'up').sum() / len(direction) * 100)\n",
    "    amount_error = y_pred - y_test\n",
    "    percent_error = amount_error / y_test * 100\n",
    "    # correct if same direction and error within 1%\n",
    "\n",
    "    correct = (direction == actual_direction) & (abs(amount_error) <= 2*mean_abs_error)\n",
    "    accuracy_score = correct.sum() / len(correct) * 100\n",
    "    print(f\"Direction Accuracy using {self.future_close_day_to_predict} days: {accuracy_score}%\")\n",
    "    error_df = pd.DataFrame({'Reference open': X_test['Open'],\n",
    "                             'Direction': direction,\n",
    "                              'Correct': correct,\n",
    "                              'Amount Error': amount_error,\n",
    "                              'Error %': percent_error,\n",
    "                              'Predicted': y_pred })\n",
    "    actual_col_name = f\"Close +{self.future_close_day_to_predict} (actual)\"\n",
    "    error_df[actual_col_name] = y_test\n",
    "    # take last 10 by close\n",
    "    error_df = error_df.tail(10)\n",
    "    print(error_df.to_markdown())\n",
    "\n",
    "    # return average\n",
    "    return scores.mean(), mean_abs_error\n",
    "\n",
    "  def get_importance(self):\n",
    "    if not hasattr(self, 'model'):\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    class_name = self.model.__class__.__name__\n",
    "    if class_name == 'XGBRegressor':\n",
    "      importances = self.model.get_booster().get_score(importance_type=\"gain\")\n",
    "      # sort by importance\n",
    "      importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "    # check if pipeline\n",
    "    elif class_name == 'Pipeline':\n",
    "      try:\n",
    "        importances = self.model.named_steps['Regressor'].feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "    else:\n",
    "      try:\n",
    "        importances = self.model.feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "\n",
    "    if not importances:\n",
    "      print('Using selector model importances')\n",
    "      try:\n",
    "        importances = self.selector_model.feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "        print('error getting importances', e)\n",
    "\n",
    "    return importances\n",
    "\n",
    "  def predict(self, last_row):\n",
    "    # predict\n",
    "    X = last_row.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    # y = last_row['next_close']\n",
    "    y_pred = self.model.predict(X)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coins.json already exists\n",
      "loading data from coingecko 1705784964 1737320964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b0/q_rh_9hs551dzx3ht468zyj80000gn/T/ipykernel_89127/1187472212.py:65: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  df.index = df['time'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:495: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:496: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:501: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:526: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:531: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:536: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected columns ['Time' 'volume_adi' 'volume_nvi' 'volatility_dcl' 'volatility_dcw'\n",
      " 'volatility_ui' 'trend_ema_fast' 'trend_ema_slow' 'trend_mass_index'\n",
      " 'trend_ichimoku_conv' 'trend_ichimoku_a' 'trend_stc' 'trend_psar_down'\n",
      " 'momentum_kama' 'target' 'Open' 'Close']\n",
      "shift 29 True\n",
      "training shape (332, 16)\n",
      "training columns ['Time' 'volume_adi' 'volume_nvi' 'volatility_dcl' 'volatility_dcw'\n",
      " 'volatility_ui' 'trend_ema_fast' 'trend_ema_slow' 'trend_mass_index'\n",
      " 'trend_ichimoku_conv' 'trend_ichimoku_a' 'trend_stc' 'trend_psar_down'\n",
      " 'momentum_kama' 'Open' 'Close']\n",
      "example train rows time\n",
      "2024-12-18 00:00:00+00:00   5.83\n",
      "2024-12-19 00:00:00+00:00   5.45\n",
      "2024-12-20 00:00:00+00:00   4.97\n",
      "Name: target, dtype: float64\n",
      "\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cp = CoinPredict(symbol='fil', days_to_backtest=DAYS_TO_BACKTEST, future_close_day_to_predict=30)\n",
    "cp.get_coins_list()\n",
    "df, X_test = cp.load_data()\n",
    "cp.train_model(df, True)\n",
    "print('\\n***\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: fil - Days to compare: 4\n",
      "cross val scores\n",
      "---\n",
      "[ -8.44890347   0.09495931 -16.6949565   -3.16663809]\n",
      "Average CV: -7.05 (+/- 12.69)\n",
      "Mean Absolute Error: 0.34540326279829453\n",
      "Mean Squared Error: 0.19646320625242106\n",
      "Root Mean Squared Error: 0.4432417018427091\n",
      "R2 Score: 0.9420497667145717\n",
      "Comparing a few predictions side by side...\n",
      "Percentage of predictions that are up: 43.28358208955223\n",
      "Direction Accuracy using 30 days: 79.1044776119403%\n",
      "| time                      |   Reference open | Direction   | Correct   |   Amount Error |    Error % |   Predicted |   Close +30 (actual) |\n",
      "|:--------------------------|-----------------:|:------------|:----------|---------------:|-----------:|------------:|---------------------:|\n",
      "| 2024-03-19 00:00:00+00:00 |            8.871 | down        | True      |     -0.112689  |  -1.87908  |     5.88431 |                5.997 |\n",
      "| 2024-06-19 00:00:00+00:00 |            4.35  | up          | True      |     -0.0490281 |  -1.05256  |     4.60897 |                4.658 |\n",
      "| 2024-09-03 00:00:00+00:00 |            3.49  | up          | True      |     -0.024221  |  -0.677701 |     3.54978 |                3.574 |\n",
      "| 2024-11-15 00:00:00+00:00 |            3.86  | up          | False     |     -0.954179  | -14.1801   |     5.77482 |                6.729 |\n",
      "| 2024-11-11 00:00:00+00:00 |            4.263 | up          | True      |     -0.541716  |  -8.09982  |     6.14628 |                6.688 |\n",
      "| 2024-10-08 00:00:00+00:00 |            3.708 | up          | True      |      0.356975  |   9.47638  |     4.12398 |                3.767 |\n",
      "| 2024-01-27 00:00:00+00:00 |            5.172 | up          | True      |     -0.104657  |  -1.28397  |     8.04634 |                8.151 |\n",
      "| 2024-04-10 00:00:00+00:00 |            8.656 | down        | True      |      0.646395  |  11.4955   |     6.26939 |                5.623 |\n",
      "| 2024-09-20 00:00:00+00:00 |            3.686 | up          | True      |     -0.105032  |  -2.63636  |     3.87897 |                3.984 |\n",
      "| 2024-03-24 00:00:00+00:00 |            8.627 | down        | True      |     -0.224493  |  -3.5154   |     6.16151 |                6.386 |\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score, mean_abs_error = cp.cross_val_score(df, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FIL': {'USD': 4.973}, 'c': 4.973, 't': 1737338970.417999}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_quote = cp.get_last_quote()\n",
    "last_quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-01-19 00:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$5.16 - Close prediction at 2025-02-18 00:00:00+00:00\n",
      "$4.973 - Last price: 2025-01-19 21:09:30.417999029-05:00\n",
      "higher\n",
      "\n",
      "Mean abs error: 0.34540326279829453\n",
      "The predicted change is $0.19. The minimum threshold for action is $0.17 which is half the mean absolute prediction error.\n",
      "Buy fil\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = cp.predict(X_test)\n",
    "if mean_abs_error:\n",
    "  pred_close_date =  X_test.index[0] + pd.Timedelta(f\"{cp.future_close_day_to_predict} days\")\n",
    "  # round to 2 decimal\n",
    "  predicted_value = round(y_pred[0], 2)\n",
    "  print(f\"\\n${predicted_value} - Close prediction at {pred_close_date}\")\n",
    "\n",
    "  if last_quote:\n",
    "    last_price = float(last_quote['c']) # ex: https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=IBM&apikey=demo\n",
    "    last_price_time_seconds = last_quote['t']\n",
    "    formatted_time_in_est = pd.to_datetime(last_price_time_seconds, unit='s').tz_localize('UTC').tz_convert('US/Eastern')\n",
    "    higher_or_lower = 'higher' if predicted_value > last_price else ('lower' if predicted_value < last_price else 'same')\n",
    "    print(f\"${last_price} - Last price: {formatted_time_in_est}\\n{higher_or_lower}\")\n",
    "  else:\n",
    "    last_price = X_test['Open'].iloc[0]\n",
    "  pred_diff = predicted_value - last_price\n",
    "  print(f\"\\nMean abs error: {mean_abs_error}\")\n",
    "  # action\n",
    "  min_threshold = mean_abs_error * 0.5\n",
    "  print(f\"The predicted change is ${round(pred_diff, 2)}. The minimum threshold for action is ${round(min_threshold, 2)} which is half the mean absolute prediction error.\")\n",
    "  if pred_diff > min_threshold:\n",
    "    action = 'buy'\n",
    "  elif pred_diff < -min_threshold:\n",
    "    action = 'sell'\n",
    "  else:\n",
    "    action = 'hold'\n",
    "  print(f\"{action.capitalize()} {cp.symbol}\")\n",
    "\n",
    "# get next weekday (monday, tuesday, etc.) after X_test index - if saturday or sunday use monday\n",
    "next_weekday = X_test.index + pd.Timedelta('1 day')\n",
    "if next_weekday.day_of_week in [5, 6]:\n",
    "  next_weekday = X_test.index + pd.offsets.BDay(1)\n",
    "next_weekday = next_weekday.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
