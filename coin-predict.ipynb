{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done CG- ba1\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests_cache\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer,mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "import cryptocompare\n",
    "\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import ta\n",
    "\n",
    "# Define the parameter grid\n",
    "PARAM_GRID = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [6, 12, 24],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "RANDOM_PARAM_GRID = {\n",
    "    'n_estimators': [int(x) for x in range(50, 1000, 50)],\n",
    "    'max_depth': [None] + [int(x) for x in range(10, 110, 10)],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "XGB_PARAM_GRID= {\n",
    "    'n_estimators': [100, 500],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "BEST_PARAMS = {'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
    "\n",
    "voting_regressor = VotingRegressor([\n",
    "    ('lgr', LinearRegression()),\n",
    "    ('hist', HistGradientBoostingRegressor()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('gbm', GradientBoostingRegressor()),\n",
    "    # ('xgb', XGBRegressor())\n",
    "])\n",
    "\n",
    "ACTIVE_MODEL = Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    # ('FeatureSelection', SelectKBest(score_func=f_regression, k=10)),\n",
    "    ('Regressor', voting_regressor)\n",
    "    ]\n",
    ")\n",
    "# ACTIVE_MODEL = RandomForestRegressor(**BEST_PARAMS)\n",
    "# ACTIVE_MODEL=XGBRegressor(**{'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8})\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "PERIOD = \"5y\"\n",
    "DAYS_TO_BACKTEST = 4\n",
    "COINGECKO_KEY = os.getenv('COINGECKO_KEY')\n",
    "CC_KEY = os.getenv('CC_KEY')\n",
    "# format to 2 decimal in print\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print('done', COINGECKO_KEY[:3], CC_KEY[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests_cache.CachedSession('yfinance.cache')\n",
    "session.headers['User-agent'] = 'yfinance/1.0'\n",
    "\n",
    "class CoinPredict:\n",
    "  COLS_TO_DROP = [\n",
    "    'Conversiontype', 'Conversionsymbol', 'Volumefrom', 'Volumeto',\n",
    "    'Range', 'Volume', 'High', 'Low', 'day of week', 'month', 'Dividends', 'Coin Splits', 'Capital Gains',]\n",
    "  TARGET_COL = 'target'\n",
    "  BASE_DIR = 'data'\n",
    "\n",
    "  def __init__(self, symbol='ETH', period=PERIOD, days_to_backtest=DAYS_TO_BACKTEST, future_close_day_to_predict=1, max_features=14):\n",
    "    self.symbol = symbol\n",
    "    self.folder =  f\"{CoinPredict.BASE_DIR}/{self.symbol.lower()}\"\n",
    "    self.period = period\n",
    "    self.future_close_day_to_predict = future_close_day_to_predict\n",
    "    self.days_to_backtest = days_to_backtest\n",
    "    # https://github.com/man-c/pycoingecko\n",
    "    self.cg = CoinGeckoAPI(demo_api_key=COINGECKO_KEY)\n",
    "    cryptocompare.cryptocompare._set_api_key_parameter(CC_KEY)\n",
    "\n",
    "    self.selector_model = None\n",
    "    self.max_features = max_features\n",
    "\n",
    "  def get_coins_list(self):\n",
    "    coins = cryptocompare.get_coin_list(format=False)\n",
    "\n",
    "    # if file exists return\n",
    "    if os.path.exists(\"coins.json\"):\n",
    "      print(\"coins.json already exists\")\n",
    "      return\n",
    "\n",
    "    with open(\"coins.json\", \"w\") as f:\n",
    "      f.write(json.dumps(coins))\n",
    "\n",
    "\n",
    "  def load_data(self):\n",
    "    now = pd.Timestamp.now()\n",
    "    current_date_string = now.strftime('%Y-%m-%d')\n",
    "    data_file = f\"{self.folder}/{self.period}_{current_date_string}.csv\"\n",
    "    if not os.path.exists(self.folder):\n",
    "      # create folder if needed\n",
    "      os.makedirs(self.folder)\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "      print(\"loading data from file: \" + data_file)\n",
    "      # read 'Date' as index\n",
    "      df = pd.read_csv(data_file, header=0, index_col=0)\n",
    "    else:\n",
    "      from_timestamp = int((now - pd.Timedelta(days=int(365))).timestamp())\n",
    "      to_timestamp = int(now.timestamp())\n",
    "      print(\"loading data from coingecko\", from_timestamp, to_timestamp)\n",
    "      data = cryptocompare.get_historical_price_day(self.symbol, currency='USD',\n",
    "                                                    limit=365, toTs=to_timestamp)\n",
    "      # ,prices,market_caps,total_volumes\n",
    "      # 0,\"[1705795200000, 2470.2636151036777]\",\"[1705795200000, 296860256191.2496]\",\"[1705795200000, 4996301224.731121]\"\n",
    "      # convert this to date, price, market_cap, volume\n",
    "      # parse array from string entry\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # convert to index by grabbing first entry of df\n",
    "      # print('history metadata', self.ticker.history_metadata)\n",
    "      df = pd.DataFrame(data)\n",
    "      df.index = df['time'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "      # capitalize columns\n",
    "      df['volume'] = df['volumeto'] - df['volumefrom']\n",
    "      df.columns = [x.capitalize() for x in df.columns]\n",
    "      # TODO: add any other data here\n",
    "      # df['timestamps'] = df['prices'].apply(lambda x: x[0])\n",
    "      # # parse timestamp to date as index\n",
    "      # df.index = df['timestamps'].apply(lambda x: datetime.utcfromtimestamp(x/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "      # df['price'] = df['prices'].apply(lambda x: x[1])\n",
    "      # df['market_cap'] = df['market_caps'].apply(lambda x: x[1])\n",
    "      # df['volume'] = df['total_volumes'].apply(lambda x: x[1])\n",
    "      # df = df[['price', 'market_cap', 'volume']]\n",
    "\n",
    "      df.to_csv(data_file)\n",
    "\n",
    "    return self.process_data(df)\n",
    "\n",
    "  def get_last_quote(self):\n",
    "    if not COINGECKO_KEY:\n",
    "      return None\n",
    "\n",
    "    quote = self.cg.get_price(ids=self.symbol, vs_currencies='usd')\n",
    "    return quote\n",
    "\n",
    "\n",
    "  def process_data(self, df):\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "    # df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df['Range'] = df['High'] - df['Low']\n",
    "    for i in range(1, self.days_to_backtest):\n",
    "      df[f'close diff {i} days ago'] = df['Close'].shift(i-1) - df['Close'].shift(i)\n",
    "      df[f'volume {i} days ago'] = df['Volume'].shift(i)\n",
    "      df[f'range {i} days ago'] = df['Range'].shift(i)\n",
    "\n",
    "    for i in range(1, self.future_close_day_to_predict):\n",
    "      df['Close +'+str(i)] = df['Close'].shift(-i)\n",
    "\n",
    "    df['high yesterday'] = df['High'].shift(1)\n",
    "    df['low yesterday'] = df['Low'].shift(1)\n",
    "\n",
    "    # df[CoinPredict.TARGET_COL] =  df['Close'].shift(-1) - df['Close'] # change in close\n",
    "    df[CoinPredict.TARGET_COL] = df['Close'].shift(-self.future_close_day_to_predict) # next close\n",
    "    # df[CoinPredict.TARGET_COL] = (df['Close'].shift(-1) - df['Open']).apply(lambda x: 'up' if x > 0 else 'down') # next close direction (up or down)\n",
    "\n",
    "    # set day of week\n",
    "    # as datetime\n",
    "    df['day of week'] = df.index.day_of_week\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    from ta import add_all_ta_features\n",
    "\n",
    "    df['EMA_5'] = ta.trend.ema_indicator(df['Close'], window=5)\n",
    "    df['EMA_20'] = ta.trend.ema_indicator(df['Close'], window=20)\n",
    "    # https://github.com/bukosabino/ta\n",
    "    df = add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
    "\n",
    "    # one hot encode month and day of week\n",
    "    # df = pd.get_dummies(df, columns=['day of week', 'month'])\n",
    "\n",
    "    # drop columns (final step)\n",
    "    cols_to_drop = CoinPredict.COLS_TO_DROP\n",
    "    # if last row is missing close, drop it\n",
    "    if pd.isna(df.iloc[-1]['Close']):\n",
    "      cols_to_drop.append('Close')\n",
    "\n",
    "    df = df.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "#     print('df columns', df.columns)\n",
    "    # fill nan with mean\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "    after_close = not pd.isna(df.iloc[-1]['Close'])\n",
    "\n",
    "    shift_days = self.future_close_day_to_predict - int(after_close)\n",
    "    df = df[self.days_to_backtest:]\n",
    "\n",
    "    print('shift', shift_days, after_close)\n",
    "    if shift_days > 0:\n",
    "      df = df[:-shift_days]\n",
    "\n",
    "\n",
    "    if not self.selector_model:\n",
    "      self.selector_model = RandomForestRegressor()\n",
    "      self.selector = SelectFromModel(self.selector_model, max_features=self.max_features, threshold=-np.inf) # take top max_features\n",
    "      # define X and y\n",
    "      X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "      y_train = df[CoinPredict.TARGET_COL]\n",
    "      self.selector_model.fit(X_train, y_train)\n",
    "      self.selector.fit(X_train, y_train)\n",
    "      # get selected columns\n",
    "\n",
    "    if hasattr(self.selector, 'get_support'):\n",
    "      selected_columns = X_train.columns[self.selector.get_support()]\n",
    "      # keep target\n",
    "      for col in [CoinPredict.TARGET_COL, 'Open', 'Close']:\n",
    "        if col not in selected_columns:\n",
    "          selected_columns = np.append(selected_columns, col)\n",
    "      print('selected columns', selected_columns)\n",
    "      df = df[selected_columns]\n",
    "\n",
    "    last_row = df.tail(1)\n",
    "\n",
    "    return df[:-1], last_row\n",
    "\n",
    "\n",
    "  def plot_data(self, df):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('Close Price History')\n",
    "    # plot with date\n",
    "    X = df.index\n",
    "    y = df['Close']\n",
    "    plt.plot(X,y)\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "  def train_model(self, df, debug=False):\n",
    "    # define X and y\n",
    "    X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    self.trained_columns = X_train.columns.values\n",
    "    if debug:\n",
    "      print('training shape', X_train.shape)\n",
    "      print('training columns', X_train.columns.values)\n",
    "    y_train = df[CoinPredict.TARGET_COL]\n",
    "    # split data\n",
    "\n",
    "    # create regressor\n",
    "    self.model = ACTIVE_MODEL#(**PARAMS)\n",
    "\n",
    "    # fit model\n",
    "    self.model.fit(X_train, y_train)\n",
    "    print('example train rows', y_train[-3:])\n",
    "\n",
    "  def param_search(self, df, random_search=True):\n",
    "    if not self.model:\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    # define X and y\n",
    "    X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    y_train = df[CoinPredict.TARGET_COL]\n",
    "    if random_search:\n",
    "      grid_search = RandomizedSearchCV(estimator=self.model,\n",
    "                                   param_distributions=XGB_PARAM_GRID,\n",
    "                                   n_iter=100,\n",
    "                                   cv=5,\n",
    "                                   verbose=2,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "    else:\n",
    "      grid_search = GridSearchCV(estimator=self.model, param_grid=PARAM_GRID,\n",
    "                            scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n",
    "    # Perform the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    return best_params, best_score\n",
    "\n",
    "  def cross_val_score(self, df, debug=False, cv=4):\n",
    "    if not hasattr(self, 'model'):\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    X = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    y = df[CoinPredict.TARGET_COL]\n",
    "    scores = cross_val_score(self.model, X, y, cv=cv)\n",
    "    print(f\"Symbol: {self.symbol} - Days to compare: {self.days_to_backtest}\\ncross val scores\\n---\\n{scores}\")\n",
    "\n",
    "    # print other stats\n",
    "    print(\"Average CV: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    model = ACTIVE_MODEL\n",
    "\n",
    "    # test train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mean_abs_error = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    if debug:\n",
    "      print('Mean Absolute Error:', mean_abs_error)\n",
    "      print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "      print('Root Mean Squared Error:', rmse)\n",
    "      print('R2 Score:', metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "    direction = y_pred - X_test['Open']\n",
    "    direction = direction.apply(lambda x: 'up' if x > 0 else 'down')\n",
    "    actual_direction = y_test - X_test['Open']\n",
    "    actual_direction = actual_direction.apply(lambda x: 'up' if x > 0 else 'down')\n",
    "\n",
    "    # print a few comparisons\n",
    "    print('Comparing a few predictions side by side...')\n",
    "    amount_error = y_pred - y_test\n",
    "    percent_error = amount_error / y_test * 100\n",
    "    # correct if same direction and error within 1%\n",
    "\n",
    "    correct = (direction == actual_direction) & (abs(amount_error) <= 2*mean_abs_error)\n",
    "    accuracy_score = correct.sum() / len(correct) * 100\n",
    "    print(f\"Direction Accuracy using {self.future_close_day_to_predict} days: {accuracy_score}%\")\n",
    "    error_df = pd.DataFrame({'Reference open': X_test['Open'],\n",
    "                             'Direction': direction,\n",
    "                              'Correct': correct,\n",
    "                              'Amount Error': amount_error,\n",
    "                              'Error %': percent_error,\n",
    "                              'Predicted': y_pred })\n",
    "    actual_col_name = f\"Close +{self.future_close_day_to_predict} (actual)\"\n",
    "    error_df[actual_col_name] = y_test\n",
    "    # take last 10 by close\n",
    "    error_df = error_df.tail(10)\n",
    "    print(error_df.to_markdown())\n",
    "\n",
    "    # return average\n",
    "    return scores.mean(), mean_abs_error\n",
    "\n",
    "  def get_importance(self):\n",
    "    if not hasattr(self, 'model'):\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    class_name = self.model.__class__.__name__\n",
    "    if class_name == 'XGBRegressor':\n",
    "      importances = self.model.get_booster().get_score(importance_type=\"gain\")\n",
    "      # sort by importance\n",
    "      importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "    # check if pipeline\n",
    "    elif class_name == 'Pipeline':\n",
    "      try:\n",
    "        importances = self.model.named_steps['Regressor'].feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "    else:\n",
    "      try:\n",
    "        importances = self.model.feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "\n",
    "    if not importances:\n",
    "      print('Using selector model importances')\n",
    "      try:\n",
    "        importances = self.selector_model.feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "        print('error getting importances', e)\n",
    "\n",
    "    return importances\n",
    "\n",
    "  def predict(self, last_row):\n",
    "    # predict\n",
    "    X = last_row.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    # y = last_row['next_close']\n",
    "    y_pred = self.model.predict(X)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coins.json already exists\n",
      "loading data from file: data/eth/5y_2025-01-19.csv\n",
      "shift 0 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:496: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:501: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:526: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:531: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:536: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected columns ['Open' 'Close' 'close diff 3 days ago' 'high yesterday' 'EMA_5'\n",
      " 'volume_obv' 'volume_vpt' 'volume_nvi' 'volatility_ui' 'trend_mass_index'\n",
      " 'trend_kst_sig' 'trend_adx' 'trend_adx_pos' 'others_cr' 'target']\n",
      "training shape (361, 14)\n",
      "training columns ['Open' 'Close' 'close diff 3 days ago' 'high yesterday' 'EMA_5'\n",
      " 'volume_obv' 'volume_vpt' 'volume_nvi' 'volatility_ui' 'trend_mass_index'\n",
      " 'trend_kst_sig' 'trend_adx' 'trend_adx_pos' 'others_cr']\n",
      "example train rows time\n",
      "2025-01-16 00:00:00+00:00   3475.27\n",
      "2025-01-17 00:00:00+00:00   3304.42\n",
      "2025-01-18 00:00:00+00:00   3210.82\n",
      "Name: target, dtype: float64\n",
      "\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cp = CoinPredict(symbol='eth', days_to_backtest=DAYS_TO_BACKTEST, future_close_day_to_predict=1)\n",
    "cp.get_coins_list()\n",
    "df, X_test = cp.load_data()\n",
    "cp.train_model(df, True)\n",
    "print('\\n***\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: eth - Days to compare: 4\n",
      "cross val scores\n",
      "---\n",
      "[0.94428908 0.84639636 0.79390042 0.90796964]\n",
      "Average CV: 0.87 (+/- 0.12)\n",
      "Mean Absolute Error: 69.75111520021339\n",
      "Mean Squared Error: 9275.812032832338\n",
      "Root Mean Squared Error: 96.31101719342568\n",
      "R2 Score: 0.9620269114272784\n",
      "Comparing a few predictions side by side...\n",
      "Direction Accuracy using 1 days: 67.12328767123287%\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/personal/python/coin-predict/env/lib/python3.12/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.8/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_cv_score, mean_abs_error \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[106], line 287\u001b[0m, in \u001b[0;36mCoinPredict.cross_val_score\u001b[0;34m(self, df, debug, cv)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# take last 10 by close\u001b[39;00m\n\u001b[1;32m    286\u001b[0m error_df \u001b[38;5;241m=\u001b[39m error_df\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43merror_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# return average\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mmean(), mean_abs_error\n",
      "File \u001b[0;32m~/personal/python/coin-predict/env/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/personal/python/coin-predict/env/lib/python3.12/site-packages/pandas/core/frame.py:2983\u001b[0m, in \u001b[0;36mDataFrame.to_markdown\u001b[0;34m(self, buf, mode, index, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtablefmt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2982\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshowindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, index)\n\u001b[0;32m-> 2983\u001b[0m tabulate \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtabulate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m result \u001b[38;5;241m=\u001b[39m tabulate\u001b[38;5;241m.\u001b[39mtabulate(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/personal/python/coin-predict/env/lib/python3.12/site-packages/pandas/compat/_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate."
     ]
    }
   ],
   "source": [
    "mean_cv_score, mean_abs_error = cp.cross_val_score(df, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
