{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done CG- ba1\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests_cache\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer,mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "import cryptocompare\n",
    "\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import ta\n",
    "\n",
    "# Define the parameter grid\n",
    "PARAM_GRID = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [6, 12, 24],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "RANDOM_PARAM_GRID = {\n",
    "    'n_estimators': [int(x) for x in range(50, 1000, 50)],\n",
    "    'max_depth': [None] + [int(x) for x in range(10, 110, 10)],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "XGB_PARAM_GRID= {\n",
    "    'n_estimators': [100, 500],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "BEST_PARAMS = {'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
    "\n",
    "voting_regressor = VotingRegressor([\n",
    "    ('lgr', LinearRegression()),\n",
    "    ('hist', HistGradientBoostingRegressor()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('gbm', GradientBoostingRegressor()),\n",
    "    # ('xgb', XGBRegressor())\n",
    "])\n",
    "\n",
    "ACTIVE_MODEL = Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    # ('FeatureSelection', SelectKBest(score_func=f_regression, k=10)),\n",
    "    ('Regressor', voting_regressor)\n",
    "    ]\n",
    ")\n",
    "# ACTIVE_MODEL = RandomForestRegressor(**BEST_PARAMS)\n",
    "# ACTIVE_MODEL=XGBRegressor(**{'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8})\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "PERIOD = 365\n",
    "DAYS_TO_BACKTEST = 4\n",
    "COINGECKO_KEY = os.getenv('COINGECKO_KEY')\n",
    "CC_KEY = os.getenv('CC_KEY')\n",
    "# format to 2 decimal in print\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print('done', COINGECKO_KEY[:3], CC_KEY[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CoinPredict:\n",
    "  COLS_TO_DROP = [\n",
    "    'Conversiontype', 'Conversionsymbol', 'Volumefrom', 'Volumeto',\n",
    "    'Range', 'Volume', 'High', 'Low', 'day of week', 'month', 'Dividends', 'Coin Splits', 'Capital Gains',]\n",
    "  TARGET_COL = 'target'\n",
    "  BASE_DIR = 'data'\n",
    "\n",
    "  def __init__(self, symbol='ETH', period=PERIOD, days_to_backtest=DAYS_TO_BACKTEST, future_close_day_to_predict=1, max_features=14):\n",
    "    self.symbol = symbol\n",
    "    self.folder =  f\"{CoinPredict.BASE_DIR}/{self.symbol.lower()}\"\n",
    "    self.period = period\n",
    "    self.future_close_day_to_predict = future_close_day_to_predict\n",
    "    self.days_to_backtest = days_to_backtest\n",
    "    # https://github.com/man-c/pycoingecko\n",
    "    self.cg = CoinGeckoAPI(demo_api_key=COINGECKO_KEY)\n",
    "    cryptocompare.cryptocompare._set_api_key_parameter(CC_KEY)\n",
    "\n",
    "    self.selector_model = None\n",
    "    self.max_features = max_features\n",
    "\n",
    "  def get_coins_list(self):\n",
    "    coins = cryptocompare.get_coin_list(format=False)\n",
    "\n",
    "    # if file exists return\n",
    "    if os.path.exists(\"coins.json\"):\n",
    "      print(\"coins.json already exists\")\n",
    "    else:\n",
    "      with open(\"coins.json\", \"w\") as f:\n",
    "        f.write(json.dumps(coins))\n",
    "\n",
    "    symbol_file = \"coins_short.json\"\n",
    "    symbols = []\n",
    "    for k, v in coins.items():\n",
    "      symbols.append({\n",
    "        'id': v['Id'],\n",
    "        'symbol': v['Symbol'],\n",
    "        'name': v['Name']\n",
    "      })\n",
    "    with open(symbol_file, \"w\") as f:\n",
    "      f.write(json.dumps(symbols))\n",
    "\n",
    "\n",
    "  def load_data(self):\n",
    "    now = pd.Timestamp.now()\n",
    "    current_date_string = now.strftime('%Y-%m-%d')\n",
    "    data_file = f\"{self.folder}/{self.period}_{current_date_string}.csv\"\n",
    "    if not os.path.exists(self.folder):\n",
    "      # create folder if needed\n",
    "      os.makedirs(self.folder)\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "      print(\"loading data from file: \" + data_file)\n",
    "      # read 'Date' as index\n",
    "      df = pd.read_csv(data_file, header=0, index_col=0)\n",
    "    else:\n",
    "      from_timestamp = int((now - pd.Timedelta(days=int(self.period))).timestamp())\n",
    "      to_timestamp = int(now.timestamp())\n",
    "      print(\"loading data from coingecko\", from_timestamp, to_timestamp)\n",
    "      data = cryptocompare.get_historical_price_day(self.symbol, currency='USD',\n",
    "                                                    limit=365, toTs=to_timestamp)\n",
    "\n",
    "      # print('history metadata', self.ticker.history_metadata)\n",
    "      df = pd.DataFrame(data)\n",
    "      df.index = df['time'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "      # capitalize columns\n",
    "      df['volume'] = df['volumeto'] - df['volumefrom']\n",
    "      df.columns = [x.capitalize() for x in df.columns]\n",
    "\n",
    "    return self.process_data(df)\n",
    "\n",
    "  def get_last_quote(self):\n",
    "    if not COINGECKO_KEY:\n",
    "      return None\n",
    "\n",
    "    quote = cryptocompare.get_price(self.symbol, currency='USD', full=False)\n",
    "    quote['c'] = quote[self.symbol.upper()]['USD']\n",
    "    # now\n",
    "    quote['t'] = datetime.now().timestamp()\n",
    "\n",
    "    return quote\n",
    "\n",
    "\n",
    "  def process_data(self, df):\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "    # df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df['Range'] = df['High'] - df['Low']\n",
    "    for i in range(1, self.days_to_backtest):\n",
    "      df[f'close diff {i} days ago'] = df['Close'].shift(i-1) - df['Close'].shift(i)\n",
    "      df[f'volume {i} days ago'] = df['Volume'].shift(i)\n",
    "      df[f'range {i} days ago'] = df['Range'].shift(i)\n",
    "\n",
    "    for i in range(1, self.future_close_day_to_predict):\n",
    "      df['Close +'+str(i)] = df['Close'].shift(-i)\n",
    "\n",
    "    df['high yesterday'] = df['High'].shift(1)\n",
    "    df['low yesterday'] = df['Low'].shift(1)\n",
    "\n",
    "    # df[CoinPredict.TARGET_COL] =  df['Close'].shift(-1) - df['Close'] # change in close\n",
    "    df[CoinPredict.TARGET_COL] = df['Close'].shift(-self.future_close_day_to_predict) # next close\n",
    "    # df[CoinPredict.TARGET_COL] = (df['Close'].shift(-1) - df['Open']).apply(lambda x: 'up' if x > 0 else 'down') # next close direction (up or down)\n",
    "\n",
    "    # set day of week\n",
    "    # as datetime\n",
    "    df['day of week'] = df.index.day_of_week\n",
    "    df['month'] = df.index.month\n",
    "\n",
    "    from ta import add_all_ta_features\n",
    "\n",
    "    df['EMA_5'] = ta.trend.ema_indicator(df['Close'], window=5)\n",
    "    df['EMA_20'] = ta.trend.ema_indicator(df['Close'], window=20)\n",
    "    # https://github.com/bukosabino/ta\n",
    "    df = add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
    "\n",
    "    # one hot encode month and day of week\n",
    "    # df = pd.get_dummies(df, columns=['day of week', 'month'])\n",
    "\n",
    "    # drop columns (final step)\n",
    "    cols_to_drop = CoinPredict.COLS_TO_DROP\n",
    "    # if last row is missing close, drop it\n",
    "    if pd.isna(df.iloc[-1]['Close']):\n",
    "      cols_to_drop.append('Close')\n",
    "\n",
    "    df = df.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "#     print('df columns', df.columns)\n",
    "    # fill nan with mean\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "    after_close = not pd.isna(df.iloc[-1]['Close'])\n",
    "\n",
    "    shift_days = self.future_close_day_to_predict - int(after_close)\n",
    "    df = df[self.days_to_backtest:]\n",
    "\n",
    "    print('shift', shift_days, after_close)\n",
    "    if shift_days > 0:\n",
    "      df = df[:-shift_days]\n",
    "\n",
    "\n",
    "    if not self.selector_model:\n",
    "      self.selector_model = RandomForestRegressor()\n",
    "      self.selector = SelectFromModel(self.selector_model, max_features=self.max_features, threshold=-np.inf) # take top max_features\n",
    "      # define X and y\n",
    "      X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "      y_train = df[CoinPredict.TARGET_COL]\n",
    "      self.selector_model.fit(X_train, y_train)\n",
    "      self.selector.fit(X_train, y_train)\n",
    "      # get selected columns\n",
    "\n",
    "    if hasattr(self.selector, 'get_support'):\n",
    "      selected_columns = X_train.columns[self.selector.get_support()]\n",
    "      # keep target\n",
    "      for col in [CoinPredict.TARGET_COL, 'Open', 'Close']:\n",
    "        if col not in selected_columns:\n",
    "          selected_columns = np.append(selected_columns, col)\n",
    "      print('selected columns', selected_columns)\n",
    "      df = df[selected_columns]\n",
    "\n",
    "    last_row = df.tail(1)\n",
    "\n",
    "    return df[:-1], last_row\n",
    "\n",
    "\n",
    "  def plot_data(self, df):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('Close Price History')\n",
    "    # plot with date\n",
    "    X = df.index\n",
    "    y = df['Close']\n",
    "    plt.plot(X,y)\n",
    "    plt.xlabel('Date', fontsize=18)\n",
    "    plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "  def train_model(self, df, debug=False):\n",
    "    # define X and y\n",
    "    X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    self.trained_columns = X_train.columns.values\n",
    "    if debug:\n",
    "      print('training shape', X_train.shape)\n",
    "      print('training columns', X_train.columns.values)\n",
    "    y_train = df[CoinPredict.TARGET_COL]\n",
    "    # split data\n",
    "\n",
    "    # create regressor\n",
    "    self.model = ACTIVE_MODEL#(**PARAMS)\n",
    "\n",
    "    # fit model\n",
    "    self.model.fit(X_train, y_train)\n",
    "    print('example train rows', y_train[-3:])\n",
    "\n",
    "  def param_search(self, df, random_search=True):\n",
    "    if not self.model:\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    # define X and y\n",
    "    X_train = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    y_train = df[CoinPredict.TARGET_COL]\n",
    "    if random_search:\n",
    "      grid_search = RandomizedSearchCV(estimator=self.model,\n",
    "                                   param_distributions=XGB_PARAM_GRID,\n",
    "                                   n_iter=100,\n",
    "                                   cv=5,\n",
    "                                   verbose=2,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "    else:\n",
    "      grid_search = GridSearchCV(estimator=self.model, param_grid=PARAM_GRID,\n",
    "                            scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n",
    "    # Perform the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    return best_params, best_score\n",
    "\n",
    "  def cross_val_score(self, df, debug=False, cv=4):\n",
    "    if not hasattr(self, 'model'):\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    X = df.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    y = df[CoinPredict.TARGET_COL]\n",
    "    scores = cross_val_score(self.model, X, y, cv=cv)\n",
    "    print(f\"Symbol: {self.symbol} - Days to compare: {self.days_to_backtest}\\ncross val scores\\n---\\n{scores}\")\n",
    "\n",
    "    # print other stats\n",
    "    print(\"Average CV: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    model = ACTIVE_MODEL\n",
    "\n",
    "    # test train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mean_abs_error = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    if debug:\n",
    "      print('Mean Absolute Error:', mean_abs_error)\n",
    "      print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "      print('Root Mean Squared Error:', rmse)\n",
    "      print('R2 Score:', metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "    direction = y_pred - X_test['Open']\n",
    "    direction = direction.apply(lambda x: 'up' if x > 0 else 'down')\n",
    "    actual_direction = y_test - X_test['Open']\n",
    "    actual_direction = actual_direction.apply(lambda x: 'up' if x > 0 else 'down')\n",
    "\n",
    "    # print a few comparisons\n",
    "    print('Comparing a few predictions side by side...')\n",
    "    amount_error = y_pred - y_test\n",
    "    percent_error = amount_error / y_test * 100\n",
    "    # correct if same direction and error within 1%\n",
    "\n",
    "    correct = (direction == actual_direction) & (abs(amount_error) <= 2*mean_abs_error)\n",
    "    accuracy_score = correct.sum() / len(correct) * 100\n",
    "    print(f\"Direction Accuracy using {self.future_close_day_to_predict} days: {accuracy_score}%\")\n",
    "    error_df = pd.DataFrame({'Reference open': X_test['Open'],\n",
    "                             'Direction': direction,\n",
    "                              'Correct': correct,\n",
    "                              'Amount Error': amount_error,\n",
    "                              'Error %': percent_error,\n",
    "                              'Predicted': y_pred })\n",
    "    actual_col_name = f\"Close +{self.future_close_day_to_predict} (actual)\"\n",
    "    error_df[actual_col_name] = y_test\n",
    "    # take last 10 by close\n",
    "    error_df = error_df.tail(10)\n",
    "    print(error_df.to_markdown())\n",
    "\n",
    "    # return average\n",
    "    return scores.mean(), mean_abs_error\n",
    "\n",
    "  def get_importance(self):\n",
    "    if not hasattr(self, 'model'):\n",
    "      raise Exception('model not trained')\n",
    "\n",
    "    class_name = self.model.__class__.__name__\n",
    "    if class_name == 'XGBRegressor':\n",
    "      importances = self.model.get_booster().get_score(importance_type=\"gain\")\n",
    "      # sort by importance\n",
    "      importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "    # check if pipeline\n",
    "    elif class_name == 'Pipeline':\n",
    "      try:\n",
    "        importances = self.model.named_steps['Regressor'].feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "    else:\n",
    "      try:\n",
    "        importances = self.model.feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "\n",
    "    if not importances:\n",
    "      print('Using selector model importances')\n",
    "      try:\n",
    "        importances = self.selector_model.feature_importances_\n",
    "        importances = sorted(zip(self.trained_columns, importances), key=lambda x: x[1], reverse=True)\n",
    "      except Exception as e:\n",
    "        importances = []\n",
    "        print('error getting importances', e)\n",
    "\n",
    "    return importances\n",
    "\n",
    "  def predict(self, last_row):\n",
    "    # predict\n",
    "    X = last_row.drop([CoinPredict.TARGET_COL], axis=1)\n",
    "    # y = last_row['next_close']\n",
    "    y_pred = self.model.predict(X)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coins.json already exists\n",
      "loading data from file: data/eth/365_2025-01-19.csv\n",
      "shift 4 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:487: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo\"] = indicator_ppo.ppo()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:488: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_signal\"] = indicator_ppo.ppo_signal()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:489: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_ppo_hist\"] = indicator_ppo.ppo_hist()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:495: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo\"] = indicator_pvo.pvo()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:496: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_signal\"] = indicator_pvo.pvo_signal()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_pvo_hist\"] = indicator_pvo.pvo_hist()\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:501: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}momentum_kama\"] = KAMAIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:526: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dr\"] = DailyReturnIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:531: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_dlr\"] = DailyLogReturnIndicator(\n",
      "/Users/chrisbuonocore/personal/python/coin-predict/env/lib/python3.12/site-packages/ta/wrapper.py:536: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{colprefix}others_cr\"] = CumulativeReturnIndicator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected columns ['Time' 'volume 1 days ago' 'range 1 days ago' 'close diff 2 days ago'\n",
      " 'volume 3 days ago' 'Close +2' 'Close +3' 'Close +4' 'volume_nvi'\n",
      " 'trend_mass_index' 'trend_kst_sig' 'trend_adx' 'trend_adx_pos'\n",
      " 'momentum_stoch_rsi_d' 'target' 'Open' 'Close']\n",
      "training shape (357, 16)\n",
      "training columns ['Time' 'volume 1 days ago' 'range 1 days ago' 'close diff 2 days ago'\n",
      " 'volume 3 days ago' 'Close +2' 'Close +3' 'Close +4' 'volume_nvi'\n",
      " 'trend_mass_index' 'trend_kst_sig' 'trend_adx' 'trend_adx_pos'\n",
      " 'momentum_stoch_rsi_d' 'Open' 'Close']\n",
      "example train rows time\n",
      "2025-01-12 00:00:00+00:00   3475.27\n",
      "2025-01-13 00:00:00+00:00   3304.42\n",
      "2025-01-14 00:00:00+00:00   3210.82\n",
      "Name: target, dtype: float64\n",
      "\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cp = CoinPredict(symbol='eth', days_to_backtest=DAYS_TO_BACKTEST, future_close_day_to_predict=5)\n",
    "cp.get_coins_list()\n",
    "df, X_test = cp.load_data()\n",
    "cp.train_model(df, True)\n",
    "print('\\n***\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: eth - Days to compare: 4\n",
      "cross val scores\n",
      "---\n",
      "[0.94040282 0.84327381 0.75495221 0.88597922]\n",
      "Average CV: 0.86 (+/- 0.14)\n",
      "Mean Absolute Error: 74.81698774826418\n",
      "Mean Squared Error: 9936.631304926814\n",
      "Root Mean Squared Error: 99.6826529789753\n",
      "R2 Score: 0.9587010898473319\n",
      "Comparing a few predictions side by side...\n",
      "Direction Accuracy using 5 days: 86.11111111111111%\n",
      "| time                      |   Reference open | Direction   | Correct   |   Amount Error |   Error % |   Predicted |   Close +5 (actual) |\n",
      "|:--------------------------|-----------------:|:------------|:----------|---------------:|----------:|------------:|--------------------:|\n",
      "| 2024-08-20 00:00:00+00:00 |          2637.47 | up          | True      |        31.8771 |  1.16021  |     2779.4  |             2747.52 |\n",
      "| 2024-04-10 00:00:00+00:00 |          3504.83 | down        | True      |        49.6272 |  1.59933  |     3152.63 |             3103    |\n",
      "| 2024-04-05 00:00:00+00:00 |          3329.17 | up          | True      |      -112.067  | -3.16078  |     3433.49 |             3545.56 |\n",
      "| 2024-04-17 00:00:00+00:00 |          3085.42 | up          | True      |       -37.0946 | -1.15864  |     3164.46 |             3201.55 |\n",
      "| 2025-01-03 00:00:00+00:00 |          3452.59 | down        | True      |        82.3108 |  2.47437  |     3408.85 |             3326.54 |\n",
      "| 2024-08-08 00:00:00+00:00 |          2343.5  | up          | True      |        19.9874 |  0.739287 |     2723.59 |             2703.6  |\n",
      "| 2024-10-04 00:00:00+00:00 |          2349.81 | up          | True      |        80.5628 |  3.40152  |     2449    |             2368.44 |\n",
      "| 2024-04-26 00:00:00+00:00 |          3155.47 | down        | True      |        40.6675 |  1.36982  |     3009.49 |             2968.82 |\n",
      "| 2024-10-31 00:00:00+00:00 |          2658.35 | down        | True      |        48.2009 |  1.9898   |     2470.6  |             2422.4  |\n",
      "| 2024-08-06 00:00:00+00:00 |          2420.39 | up          | True      |        70.6545 |  2.76462  |     2626.32 |             2555.67 |\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score, mean_abs_error = cp.cross_val_score(df, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ETH': {'USD': 3200.29}, 'c': 3200.29, 't': 1737335550.083531}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_quote = cp.get_last_quote()\n",
    "last_quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>volume 1 days ago</th>\n",
       "      <th>range 1 days ago</th>\n",
       "      <th>close diff 2 days ago</th>\n",
       "      <th>volume 3 days ago</th>\n",
       "      <th>Close +2</th>\n",
       "      <th>Close +3</th>\n",
       "      <th>Close +4</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>trend_adx</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "      <th>momentum_stoch_rsi_d</th>\n",
       "      <th>target</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-15 00:00:00+00:00</th>\n",
       "      <td>1736899200</td>\n",
       "      <td>1982124076.85</td>\n",
       "      <td>131.22</td>\n",
       "      <td>87.89</td>\n",
       "      <td>676336363.29</td>\n",
       "      <td>3475.27</td>\n",
       "      <td>3304.42</td>\n",
       "      <td>3210.82</td>\n",
       "      <td>1575.63</td>\n",
       "      <td>23.79</td>\n",
       "      <td>-57.29</td>\n",
       "      <td>24.06</td>\n",
       "      <td>19.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3105.32</td>\n",
       "      <td>3224.35</td>\n",
       "      <td>3451.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Time  volume 1 days ago  range 1 days ago  \\\n",
       "time                                                                         \n",
       "2025-01-15 00:00:00+00:00  1736899200      1982124076.85            131.22   \n",
       "\n",
       "                           close diff 2 days ago  volume 3 days ago  Close +2  \\\n",
       "time                                                                            \n",
       "2025-01-15 00:00:00+00:00                  87.89       676336363.29   3475.27   \n",
       "\n",
       "                           Close +3  Close +4  volume_nvi  trend_mass_index  \\\n",
       "time                                                                          \n",
       "2025-01-15 00:00:00+00:00   3304.42   3210.82     1575.63             23.79   \n",
       "\n",
       "                           trend_kst_sig  trend_adx  trend_adx_pos  \\\n",
       "time                                                                 \n",
       "2025-01-15 00:00:00+00:00         -57.29      24.06          19.11   \n",
       "\n",
       "                           momentum_stoch_rsi_d  target    Open   Close  \n",
       "time                                                                     \n",
       "2025-01-15 00:00:00+00:00                  0.17 3105.32 3224.35 3451.52  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$3209.87 - Close prediction at 2025-01-20 00:00:00+00:00\n",
      "$3200.29 - Last price: 2025-01-19 20:12:30.083530903-05:00\n",
      "higher\n",
      "\n",
      "Mean abs error: 74.81698774826418\n",
      "The predicted change is $9.58. The minimum threshold for action is $37.41 which is half the mean absolute prediction error.\n",
      "Hold eth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = cp.predict(X_test)\n",
    "if mean_abs_error:\n",
    "  pred_close_date =  X_test.index[0] + pd.Timedelta(f\"{cp.future_close_day_to_predict} days\")\n",
    "  # round to 2 decimal\n",
    "  predicted_value = round(y_pred[0], 2)\n",
    "  print(f\"\\n${predicted_value} - Close prediction at {pred_close_date}\")\n",
    "\n",
    "  if last_quote:\n",
    "    last_price = float(last_quote['c']) # ex: https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=IBM&apikey=demo\n",
    "    last_price_time_seconds = last_quote['t']\n",
    "    formatted_time_in_est = pd.to_datetime(last_price_time_seconds, unit='s').tz_localize('UTC').tz_convert('US/Eastern')\n",
    "    higher_or_lower = 'higher' if predicted_value > last_price else ('lower' if predicted_value < last_price else 'same')\n",
    "    print(f\"${last_price} - Last price: {formatted_time_in_est}\\n{higher_or_lower}\")\n",
    "  else:\n",
    "    last_price = X_test['Open'].iloc[0]\n",
    "  pred_diff = predicted_value - last_price\n",
    "  print(f\"\\nMean abs error: {mean_abs_error}\")\n",
    "  # action\n",
    "  min_threshold = mean_abs_error * 0.5\n",
    "  print(f\"The predicted change is ${round(pred_diff, 2)}. The minimum threshold for action is ${round(min_threshold, 2)} which is half the mean absolute prediction error.\")\n",
    "  if pred_diff > min_threshold:\n",
    "    action = 'buy'\n",
    "  elif pred_diff < -min_threshold:\n",
    "    action = 'sell'\n",
    "  else:\n",
    "    action = 'hold'\n",
    "  print(f\"{action.capitalize()} {cp.symbol}\")\n",
    "\n",
    "# get next weekday (monday, tuesday, etc.) after X_test index - if saturday or sunday use monday\n",
    "next_weekday = X_test.index + pd.Timedelta('1 day')\n",
    "if next_weekday.day_of_week in [5, 6]:\n",
    "  next_weekday = X_test.index + pd.offsets.BDay(1)\n",
    "next_weekday = next_weekday.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
